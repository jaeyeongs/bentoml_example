# BentoML 실습해보기

[MLflow 실습](https://github.com/jaeyeongs/mlflow_example) 레파지토리에 이어 여러 BentoML 프레임워크 사용법을 알아보았다.
BentoML은 API Serving이 편리하다는 장점이 있어 이를 활용하고자 한다. 추가로 BentoML은 MLFlow를 지원하기 때문에 모델 관리는 MLflow, API Serving은 BentoML 두 가지의 프레임워크를 동시에 활용하여 모델 관리 및 배포까지의 과정을 살펴본다.

## 개발 환경

```
python=3.8
mlflow>=1.0
scipy
scikit-learn
bentoml>=1.0.0rc3
```

## BentoML 실행

### BentoML Build

### Docker image

### API Serving

## BentoML를 활용한 MLFlow

### 연동

### MLFlow를 통한 실험 모델 및 결과


## 실습 결론
